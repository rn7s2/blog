# Async Rust: A Naive Work Queue Using Channel

When doing I/O intensive work such as web crawling, we might want an async work queue to maximize the performance of our crawlers.

This post demonstrates how to implement a simple (and naive) async work queue in `Rust` and how to use `Channel` to perform `ITC`
(Inter-Thread Communication).

## Before you read, you should know...

- basic concepts of `Channel` or `CSP (Communicating Sequential Processes)`
- basic ideas of `asynchronous`, `parallel`, and `concurrent`.  
  note that they are different concepts, and should not be confused with each other.
- basic knowledge of `Rust`
- basic knowledge of `cargo` to manage dependencies and the build process \
  (this post won't demo how to build and run the program)

## TL;DR (Too Long; Didn't Read)

### Dependencies

```toml
[dependencies]
tokio = { version = "1", features = ["full"] }
```

### Source Code

```rust,editable
use std::sync::Arc;
use tokio::{
    sync::{mpsc::channel, Mutex},
    task::JoinSet,
};

const WORKERS: usize = 3;

// parameters needed by a task
struct JobParam {
    val: usize,
}

// do workers' jobs
async fn process(id: usize, v: JobParam) {
    let sleep_secs = tokio::time::Duration::from_secs(id as u64 + 1);
    println!(
        "worker {}, processing #{}, estimated time: {}s",
        id,
        v.val,
        sleep_secs.as_secs()
    );
    tokio::time::sleep(sleep_secs).await;
    println!("worker {}, finished processing #{}", id, v.val);
}

#[tokio::main]
async fn main() {
    let mut tasks = JoinSet::new();

    let (tx, rx) = channel(WORKERS);
    let rx = Arc::new(Mutex::new(rx));

    for i in 0..WORKERS {
        let rx = rx.clone();
        tasks.spawn(async move {
            loop {
                // receive a value from the channel
                let v = {
                    let mut guard = rx.lock().await;
                    guard.recv().await
                    // mutex guard are dropped here
                };
                if let Some(v) = v {
                    process(i, v).await;
                } else {
                    // no more values to receive
                    break;
                }
            }
        });
    }

    // note: we shoudn't just .expect or .unwrap in production code
    //       for simplicity, we just panic here if any error occurs

    // dispatch jobs to workers
    for i in 0..10 {
        tx.send(JobParam { val: i })
            .await
            .expect("send params to workers failed.");
    }
    // drop the sender to close the channel
    // or the workers will be blocked forever
    drop(tx);

    // wait all tasks to finish
    while let Some(res) = tasks.join_next().await {
        res.expect("worker failed.");
    }
}
```

### Output

```
worker 0, processing #0, estimated time: 1s
worker 2, processing #1, estimated time: 3s
worker 1, processing #2, estimated time: 2s
worker 0, finished processing #0
worker 0, processing #3, estimated time: 1s
worker 0, finished processing #3
worker 1, finished processing #2
worker 1, processing #5, estimated time: 2s
worker 0, processing #4, estimated time: 1s
worker 2, finished processing #1
worker 2, processing #6, estimated time: 3s
worker 0, finished processing #4
worker 0, processing #7, estimated time: 1s
worker 0, finished processing #7
worker 1, finished processing #5
worker 1, processing #9, estimated time: 2s
worker 0, processing #8, estimated time: 1s
worker 0, finished processing #8
worker 2, finished processing #6
worker 1, finished processing #9
```

## Spawn some workers and store them into a `JoinSet`

```rust
const WORKERS: usize = 3;

let mut tasks = JoinSet::new();

for i in 0..WORKERS {
    tasks.spawn(async move {
        loop {
            todo!("receive JobParam and do the actual work");
        }
    });
}
```

## Create a fixed-size `Channel`

```rust
let (tx, rx) = channel(WORKERS);
let rx = Arc::new(Mutex::new(rx));
```

A channel is a pair of `Sender` and `Receiver`.
This channel can contains up to `WORKERS` elements, then it will block the sender's thread until there's free room in the channel.

Although `tokio`'s mpsc channel is `Send + Sync`, it requres `&mut self` to receive a value, which means it can't be shared across threads directly. We need some kind of interior mutability to achieve this.

If you wanted to share a `Receiver` across multiple threads without interior mutability, you could use `crossbeam` channel instead.

To share `rx` (the `Receiver`) across workers, an `Arc<Mutex<>>` is needed to hold the ownership of the `rx` and only allows one thread to acquire the lock simultaneously.

## Receive `JobParam` in workers and do the actual job

```rust
// parameters needed by a task
struct JobParam {
    val: usize,
}

// do workers' jobs
async fn process(id: usize, v: JobParam) {
    let sleep_secs = tokio::time::Duration::from_secs(id as u64 + 1);
    println!(
        "worker {}, processing #{}, estimated time: {}s",
        id,
        v.val,
        sleep_secs.as_secs()
    );
    tokio::time::sleep(sleep_secs).await;
    println!("worker {}, finished processing #{}", id, v.val);
}
```

`JobParam` is all information needed by a worker to do its job.

Then, we fill the `todo!` earlier with fllowing code:

```rust
for i in 0..WORKERS {
    let rx = rx.clone();
    tasks.spawn(async move {
        loop {
            // receive a value from the channel
            let v = {
                let mut guard = rx.lock().await;
                guard.recv().await
                // mutex guard are dropped here
            };
            if let Some(v) = v {
                process(i, v).await;
            } else {
                // no more values to receive
                break;
            }
        }
    });
}
```

We need to clone the `Arc` so that we can move the reference into the async block. Then we can use it as a regular smart pointer.

First, acquire the `Mutex` lock, and receive params from the channel.

If there's no more values, we should terminate this worker.
Otherwise, we return the lock by dropping the `MutexGuard`, and awaits
the actual process to finish.

## Dispatch `JobParams` to workers

```rust
// dispatch jobs to workers
for i in 0..20 {
    tx.send(JobParam { val: i })
        .await
        .expect("send params to workers failed.");
}
// drop the sender to close the channel
// or the workers will be blocked forever
drop(tx);
```

## Wait until all workers to finish

```rust
// wait all tasks to finish
while let Some(res) = tasks.join_next().await {
    res.expect("worker failed.");
}
```
